#normalize_samples
#' @name normalize_samples
#' @title Normalize samples
#' @description Normalize samples fastq files before de novo assembly or alignment.
#' @param path.samples (character, path) Give the path to the samples to normalize.

#' @param project.info (character, path, optional) When using the stackr pipeline,
#' a project info file is created. This file provides all the info and stats
#' generated by stacks and stackr.
#' If no \code{project.info} file is provided, the function will have to look
#' at the number of reads in the fastq files and this takes longer.
#' Default: \code{project.info = NULL}.

#' @param sample.reads (integer) The number of reads to pick randomly.
#' Default: \code{sample.reads = 1000000}.

#' @param number.samples (interger) The number of samples to generate from the sample(s) to
#' normalize.
#' Default: \code{number.samples = 5}.

#' @param random.seed (integer, optional) For reproducibility, set an integer
#' that will be used inside function that requires randomness. With default,
#' a random number is generated and printed in the appropriate output.
#' Default: \code{random.seed = NULL}.

#' @param parallel.core (optional) The number of core for parallel
#' programming.
#' Default: \code{parallel.core = parallel::detectCores() - 1}.


#' @rdname normalize_samples
#' @export
#' @importFrom stringi stri_join stri_replace_all_fixed stri_sub stri_detect_fixed
#' @importFrom dplyr mutate filter distinct
#' @importFrom purrr keep walk pwalk pmap
#' @importFrom tibble data_frame

#' @return fastq files with "-1", "-2", "..." appended to the original name
#'


#' @details
#'
#'
#' You have replicates? Awesome. stackr makes it easy to keep track of replicates.
#' Use the same name for individual replicates. They will have different barcodes,
#' and can potentially be on different lanes. No problem. stackr will combine
#' fastq file at the end, keeping original replicates intact. However, stackr
#' will be appending integers (e.g. STU-QUE-ADU-2017-0001-1, STU-QUE-ADU-2017-0001-2)
#' at the end of the names you've chosen). Combined replicates
#' will have -R at the end (e.g STU-QUE-ADU-2017-0001-R for the combination of the 2 replicates.)



#' @examples
#' \dontrun{
#' # library(stackr)
#' source("http://bioconductor.org/biocLite.R")
#' biocLite("ShortRead")
#' # Using OpenMP threads
#' nthreads <- .Call(ShortRead:::.set_omp_threads, 1L)
#' on.exit(.Call(ShortRead:::.set_omp_threads, nthreads))
#' # using defaults:
#' normalize_samples(path.samples = "~/corals")
#'
#' # customizing the function:
#' normalize_samples(
#'    project.info = "project.info.corals.tsv",
#'    path.samples = "~/corals",
#'    sample.reads = 2000000,
#'    number.samples = 5,
#'    random.seed = NULL,
#'    parallel.core = 16)
#' }


# @seealso
# \href{http://catchenlab.life.illinois.edu/stacks/comp/process_radtags.php}{process_radtags}.

# @references todo

normalize_samples <- function(
  project.info = NULL,
  path.samples,
  sample.reads = 1000000,
  number.samples = 3,
  random.seed = NULL,
  parallel.core = parallel::detectCores() - 1
) {
  cat("#######################################################################\n")
  cat("##################### stackr::normalize_samples #######################\n")
  cat("#######################################################################\n")
  timing <- proc.time()

  # Missing argument -----------------------------------------------------------
  # folder is given
  if (missing(path.samples)) stop("path.samples argument is required")

  # Check for required package -------------------------------------------------
  if (!requireNamespace("ShortRead", quietly = TRUE)) {
    stop("ShortRead needed for this function to work.
           Please follow the example for install instructions", call. = FALSE)
  }

  # import project info file if present ----------------------------------------
  if (!is.null(project.info)) {
    project.info <- suppressMessages(readr::read_tsv(file = project.info))
  }

  # Set seed for random sampling -----------------------------------------------
  if (is.null(random.seed)) {
    random.seed <- sample(x = 1:1000000, size = 1)
    set.seed(random.seed)
  } else {
    set.seed(random.seed)
  }

  fastq.files <- list_sample_file(f = path.samples, full.path = TRUE)
  # fastq.files <- fastq.files[1]#test

  purrr::walk(
    .x = fastq.files,
    .f = stackr_normalize,
    project.info = project.info,
    number.samples = number.samples,
    sample.reads = sample.reads,
    parallel.core = parallel.core)


  timing <- proc.time() - timing
  message("\nComputation time: ", round(timing[[3]]), " sec")
  cat("############################## completed ##############################\n")
}#normalize_samples


# Internal function ------------------------------------------------------------
#' @title stackr_normalize
#' @description main normalize function
#' @rdname stackr_normalize
#' @export
#' @keywords internal
stackr_normalize <- function(fastq.files, project.info, number.samples, sample.reads, parallel.core = parallel::detectCores() - 1) {
  sample.id <- stringi::stri_replace_all_fixed(
    str = fastq.files,
    pattern = unique(fq_file_type(fastq.files)),
    replacement = "", vectorize_all = FALSE)
  message("Normalizing sample: ", sample.id)

  # check number of reads
  if (is.null(project.info)) {
    n.reads <- length(ShortRead::readFastq(fastq.files))
    # length(readLines(fastq.files))
    # R.utils::countLines(fastq.files)
  } else {
    if (tibble::has_name(project.info, "RETAINED")) {
      n.reads <- dplyr::filter(project.info, FQ_FILES %in% fastq.files) %>%
        dplyr::select(RETAINED) %>%
        purrr::flatten_int(.)
    } else {
      message("Could not access the the number of reads info: checking directly fastq file")
      n.reads <- length(ShortRead::readFastq(fastq.files))
    }
  }
  message("Number of reads: ", n.reads)

  if (n.reads < sample.reads) {
    message("Number of reads the sample is lower than ", sample.reads)
    message("    skipping normalization for this sample ")
    skip.normalization <- TRUE
  } else {
  skip.normalization <- FALSE
  }

  if (!skip.normalization) {

    subsample.random <- ShortRead::FastqSampler(fastq.files, n = sample.reads, verbose = TRUE, ordered = TRUE)

    .stackr_parallel(
      X = 1:number.samples,
      FUN = write_normalize,
      mc.cores = parallel.core,
      subsample.random = subsample.random,
      fastq.files = fastq.files)
  }
  }#End stackr_normalize


#' @title write_normalize
#' @description Write the normalize fastq file
#' @rdname write_normalize
#' @export
#' @keywords internal
write_normalize <- function(number.samples, subsample.random, fastq.files) {
  message("Writing normalized samples: ", number.samples)
  new.sample <- ShortRead::yield(subsample.random)
  fq.file.type <- unique(fq_file_type(fastq.files))
  new.name <- stringi::stri_replace_all_fixed(
    str = fastq.files,
    pattern = fq.file.type,
    replacement = stringi::stri_join("-", number.samples, fq.file.type),
    vectorize_all = FALSE)
  ShortRead::writeFastq(new.sample, new.name)
}#End write_normalize
