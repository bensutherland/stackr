#normalize_samples
#' @name normalize_samples
#' @title Normalize samples
#' @description Normalize samples fastq files before de novo assembly or alignment.

#' @param project.info (character, path, optional) When using the stackr pipeline,
#' a project info file is created. This file provides all the info and stats
#' generated by stacks and stackr.
#' If no \code{project.info} file is provided, the function will have to look
#' at the number of reads in the fastq files and this will take longer.
#' The project info file will be updated with the new samples.
#' Default: \code{project.info = NULL}.

#' @param path.samples (character, path) Path of folder containing the
#' samples to normalize.

#' @param sample.reads (integer) The number of reads to pick randomly.
#' Default: \code{sample.reads = 1000000}.

#' @param number.replicates (interger) The number of samples to generate.
#' With default, if 20 samples are in the folder, 100 new samples will be generated.
#' Default: \code{number.replicates = 5}.

#' @param random.seed (integer, optional) For reproducibility, set an integer
#' that will be used inside function that requires randomness. With default,
#' a random number is generated and printed in the appropriate output.
#' Default: \code{random.seed = NULL}.

#' @param parallel.core (optional) The number of core for parallel
#' programming. Each samples to normalize is sequentially treated and replicates
#' are generated in parallel. By default, \code{parallel.core = number.replicates}.
#' Only if \code{number.replicates < parallel::detectCores()}.
#' If not, the default is \code{parallel.core = parallel::detectCores() - 1}.


#' @rdname normalize_samples
#' @export
#' @importFrom stringi stri_join stri_replace_all_fixed stri_sub stri_detect_fixed
#' @importFrom dplyr mutate filter distinct
#' @importFrom purrr keep walk pwalk pmap
#' @importFrom tibble data_frame

#' @return fastq files with "-1", "-2", "..." appended to the original name.
#' If a project info file was provided, the new replicate samples info is integrated
#' to the file. The modified project info file will have \code{_normalized} appended
#' to the original filename.
#'

#' @examples
#' \dontrun{
#' library(stackr)
#' # To run this function, bioconductor \code{ShortRead} package is necessary:
#' source("http://bioconductor.org/biocLite.R")
#' biocLite("ShortRead")
#' # Using OpenMP threads
#' nthreads <- .Call(ShortRead:::.set_omp_threads, 1L)
#' on.exit(.Call(ShortRead:::.set_omp_threads, nthreads))
#' # using defaults:
#' stackr::normalize_samples(path.samples = "~/corals")
#'
#' # customizing the function:
#' stackr::normalize_samples(
#'    project.info = "project.info.corals.tsv",
#'    path.samples = "~/corals",
#'    sample.reads = 2000000,
#'    number.replicates = 5,
#'    random.seed = 3,
#'    parallel.core = 5)
#'
#' # You then need to run stackr: run_ustacks, run_sstacks, run_tsv2bam, run_gstacks, run_populations
#' # or equivalent if a reference genome.
#' }


# @seealso
# \href{http://catchenlab.life.illinois.edu/stacks/comp/process_radtags.php}{process_radtags}.

# @references todo

normalize_samples <- function(
  project.info = NULL,
  path.samples,
  sample.reads = 1000000,
  number.replicates = 3,
  random.seed = NULL,
  parallel.core = number.replicates
) {
  opt.change <- getOption("width")
  options(width = 70)
  cat("#######################################################################\n")
  cat("##################### stackr::normalize_samples #######################\n")
  cat("#######################################################################\n")
  timing <- proc.time()

  # Missing argument -----------------------------------------------------------
  # folder is given
  if (missing(path.samples)) stop("path.samples argument is required")

  # Check for required package -------------------------------------------------
  if (!requireNamespace("ShortRead", quietly = TRUE)) {
    stop("ShortRead needed for this function to work.
           Please follow the example for install instructions", call. = FALSE)
  }

  # Check parallel.core and number.replicates -------------------------------------
  if (number.replicates > parallel::detectCores()) {
    parallel.core <- parallel::detectCores() - 1
  } else {
    parallel.core <- number.replicates
  }

  message("Setting parallel.core: ", parallel.core)

  # import project info file if present ----------------------------------------
  if (!is.null(project.info)) {
    project.info <- suppressMessages(readr::read_tsv(file = project.info))
  }

  # Set seed for random sampling -----------------------------------------------
  if (is.null(random.seed)) {
    random.seed <- sample(x = 1:1000000, size = 1)
  }
  set.seed(random.seed)

  fastq.files <- list_sample_file(f = path.samples, full.path = TRUE)
  message("Number of samples to normalize: ", length(fastq.files))
  # fastq.files <- fastq.files[1]#test

  suppressWarnings(
    purrr::walk(
      .x = fastq.files,
      .f = stackr_normalize,
      project.info = project.info,
      number.replicates = number.replicates,
      sample.reads = sample.reads,
      parallel.core = parallel.core))


  if (!is.null(project.info)) {

  }

  timing <- proc.time() - timing
  message("\nComputation time: ", round(timing[[3]]), " sec")
  cat("############################## completed ##############################\n")
  options(width = opt.change)
}#normalize_samples


# Internal function ------------------------------------------------------------
#' @title stackr_normalize
#' @description main normalize function
#' @rdname stackr_normalize
#' @export
#' @keywords internal
stackr_normalize <- function(fastq.files, project.info, number.replicates, sample.reads, parallel.core = parallel::detectCores() - 1) {
  sample.id <- stringi::stri_replace_all_fixed(
    str = fastq.files,
    pattern = unique(fq_file_type(fastq.files)),
    replacement = "", vectorize_all = FALSE)
  message("\nNormalizing sample: ", sample.id)

  # check number of reads
  if (is.null(project.info)) {
    message("    Counting the number of reads in fastq file")
    n.reads <- length(ShortRead::readFastq(fastq.files))
    # length(readLines(fastq.files))
    # R.utils::countLines(fastq.files)
  } else {
    message("    Using project info file for read counts")
    if (tibble::has_name(project.info, "RETAINED")) {
      n.reads <- dplyr::filter(project.info, FQ_FILES %in% fastq.files) %>%
        dplyr::select(RETAINED) %>%
        purrr::flatten_int(.)
    } else {
      message("        Could not access the the number of reads info")
      message("        Counting the number of reads in fastq file")
      n.reads <- length(ShortRead::readFastq(fastq.files))
      # update project.info
      project.info <- NULL
    }
  }
  message("    Number of reads: ", n.reads)

  if (n.reads < sample.reads) {
    message("    Number of reads the sample is lower than ", sample.reads)
    message("        skipping normalization for this sample ")
    skip.normalization <- TRUE
  } else {
  skip.normalization <- FALSE
  }

  if (!skip.normalization) {

    suppressWarnings(subsample.random <- ShortRead::FastqSampler(fastq.files, n = sample.reads, verbose = TRUE, ordered = TRUE))
    message("    Generating ", number.replicates, " normalized replicates")
    message("    Number of reads sampled for each replicates: ", sample.reads)
    suppressWarnings(
      .stackr_parallel_mc(
        X = 1:number.replicates,
        FUN = write_normalize,
        mc.cores = parallel.core,
        subsample.random = subsample.random,
        fastq.files = fastq.files))
  }
  }#End stackr_normalize


#' @title write_normalize
#' @description Write the normalize fastq file
#' @rdname write_normalize
#' @export
#' @keywords internal
write_normalize <- function(number.replicates, subsample.random, fastq.files) {
  message("Writing normalized samples: ", number.replicates)
  new.sample <- ShortRead::yield(subsample.random)
  fq.file.type <- unique(fq_file_type(fastq.files))
  new.name <- stringi::stri_replace_all_fixed(
    str = fastq.files,
    pattern = fq.file.type,
    replacement = stringi::stri_join("-", number.replicates, fq.file.type),
    vectorize_all = FALSE)
  suppressWarnings(ShortRead::writeFastq(new.sample, new.name))
}#End write_normalize
